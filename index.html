<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Tousif  Ahmed


</title>
<meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22></text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->






    

  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              About
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                Publications
                
              </a>
          </li>
          
          
          
          
          
          
          
          
          
          
          
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->
    
    <div class="container mt-5">
      <div id="full_page">

<div id="left_profile">
  
      <div class="profile_info">
        
          <img src="/assets/img/prof_pic.jpg">
        
        <div class="profile_details" >
          <h4 style="text-align:center; margin:10px; font-size:24px; " >
            <span class="font-weight-bold" style="color:rgb(97,50,166)">Tousif&nbsp;Ahmed</span>
          </h4>
          <h5 style="text-align:center; font-size:20px;">
           Privacy Engineer & Researcher
          </h5>
          <h5 style="text-align:center;font-size:16px;">
            Google
          </h5>
         
      
           
      <div class="social">
        <div class="contact-icons">
          <a href="mailto:%74%6F%75%61%68%6D%65%64@%69%75.%65%64%75"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=y9cQJl0AAAAJ" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/tousifeshan" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>
<a href="https://www.linkedin.com/in/tousifahmed" target="_blank" title="LinkedIn"><i class="fab fa-linkedin"></i></a>
<a href="https://twitter.com/TousifEshan" target="_blank" title="Twitter"><i class="fab fa-twitter"></i></a>












        </div>
      </div>
       <div class="full" style="text-align:center">
              <strong:><a href="/assets/pdf/resume_research.pdf" style="color: rgb(0, 0, 255);">Curriculum Vitae</a>
                </strong:>
          </div>
      
        </div>
      </div>
      
  
</div>

  <div id="post" >

    <article>
      
      <div class="profile float-left">
      
      </div>
      

      <div class="clearfix">
        <p> I am a Privacy Engineer and Applied Privacy Researcher at Google in the Devices and Services Team (DSPA). My research interests span various mobile and wearable computing topics, including privacy, accessibility, and digital health applications. At Google, our team works on improving and designing privacy-preserving technologies in Google Hardware devices, including Pixel, Fitbit, and Nest. As a privacy researcher, I am particularly interested in topics related to mobile, wearable, and smart home devices, including sensor privacy, privacy of multimodal devices, IoT privacy, health information privacy, camera privacy, and bystander privacy. Before joining Google, I spent four wonderful years at Samsung Research America, where I worked on developing novel systems for vital signs and remote patient monitoring using wearable devices.</p>

<p>I received my Ph.D. in Computer Science from the <a href="https://www.iu.edu/">Indiana University Bloomington</a>, under the supervision of Professor <a href="https://homes.luddy.indiana.edu/kapadia/">Apu Kapadia</a>. During my Ph.D., I explored the unique privacy and security concerns of people with visual impairments and designed, implemented, and evaluated solutions to address the concerns. My Ph.D. research is one of the very first works that considered the privacy and security concerns of the visually impaired and has inspired subsequent research in usable privacy and security, as well as in accessibility. Due to my contribution, I received <a href="https://luddy.indiana.edu/news/story.html?story=SICE-grad-Ahmed-earns-2019-John-Karat-Usable-Privacy-and-Security-Student-Research-Award">John Karat Usable Privacy and Security Student Research Award in 2019</a>. I have published more than 20 papers in top-tier conferences, including CHI, CSCW, ASSETS, Ubicomp, and SOUPS.</p>


      </div>
      
        <div class="news">
  <h2 style="margin:10px; font-size:24px;">News</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Mar, 2023</th>
          <td>
            
              Joined Google as a Privacy Engineer and Applied Privacy Researcher in the Devices Team.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 16, 2023</th>
          <td>
            
              Our Patent on Passive and Continuous Breathing Rate Estimation Using Earbuds is filed for US Patent !

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Feb 12, 2023</th>
          <td>
            
              Two of our papers got accepted in ICASSP 2022. The first paper is Audio based Mouth Breathing Detection using hearables and the second paper is on Inhale-Exhale RatioEstimation.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 10, 2023</th>
          <td>
            
              Our Paper on Remote Breathing Rate Monitoring is accepted at CHI 2023.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Jan 4, 2023</th>
          <td>
            
              Our Patent on “Systems and Methods To Deetct and Characterize Stress Using Physiological Sensors” is accepted for filing.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

      
      

      
        <div class="publications">
  <h2 style="margin:10px; font-size:24px;">Selected Publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IMWUT, 22</abbr>
    
  
  </div>

  <div id="10.1145/3478123" class="col-sm-8">
    
      <div class="title">BreathTrack: Detecting Regular Breathing Phases from Unannotated Acoustic Data Captured by a Smartphone</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Islam, Bashima,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Rahman, Md Mahbubur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Mohsin Yusuf,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hasan, Md Mehedi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nathan, Viswam,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vatanparvar, Korosh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nemati, Ebrahim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kuang, Jilong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gao, Jun Alex
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Breathing biomarkers, such as breathing rate, fractional inspiratory time, and inhalation-exhalation ratio, are vital for monitoring the user’s health and well-being. Accurate estimation of such biomarkers requires breathing phase detection, i.e., inhalation and exhalation. However, traditional breathing phase monitoring relies on uncomfortable equipment, e.g., chestbands. Smartphone acoustic sensors have shown promising results for passive breathing monitoring during sleep or guided breathing. However, detecting breathing phases using acoustic data can be challenging for various reasons. One of the major obstacles is the complexity of annotating breathing sounds due to inaudible parts in regular breathing and background noises. This paper assesses the potential of using smartphone acoustic sensors for passive unguided breathing phase monitoring in a natural environment. We address the annotation challenges by developing a novel variant of the teacher-student training method for transferring knowledge from an inertial sensor to an acoustic sensor, eliminating the need for manual breathing sound annotation by fusing signal processing with deep learning techniques. We train and evaluate our model on the breathing data collected from 131 subjects, including healthy individuals and respiratory patients. Experimental results show that our model can detect breathing phases with 77.33% accuracy using acoustic sensors. We further present an example use-case of breathing phase-detection by first estimating the biomarkers from the estimated breathing phases and then using these biomarkers for pulmonary patient detection. Using the detected breathing phases, we can estimate fractional inspiratory time with 92.08% accuracy, the inhalation-exhalation ratio with 86.76% accuracy, and the breathing rate with 91.74% accuracy. Moreover, we can distinguish respiratory patients from healthy individuals with up to 76% accuracy. This paper is the first to show the feasibility of detecting regular breathing phases towards passively monitoring respiratory health and well-being using acoustic data captured by a smartphone.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI, 20</abbr>
    
  
  </div>

  <div id="Chatterjee2020" class="col-sm-8">
    
      <div class="title">Assessing Severity of Pulmonary Obstruction from Respiration Phase-Based Wheeze-Sensing Using Mobile Sensors</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Chatterjee, Soujanya,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Rahman, Md Mahbubur,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Saleheen, Nazir,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nemati, Ebrahim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nathan, Viswam,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vatanparvar, Korosh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kuang, Jilong
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
      <a href="https://dl.acm.org/doi/fullHtml/10.1145/3313831.3376444" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Obstructive pulmonary diseases cause limited airflow from the lung and severely affect patients’ quality of life. Wheeze is one of the most prominent symptoms for them. High requirements imposed by traditional diagnosis methods make regular monitoring of pulmonary obstruction challenging, which hinders the opportunity of early intervention and prevention of significant exacerbation. In this work, we explore the feasibility of developing a mobile sensor-based system as a convenient means of assessing the severity of pulmonary obstruction via respiration phase-based symptomatic wheeze sensing. We conduct a 131 subjects’ (91 patients and 40 healthy) study for the detection (F1: 87.96%) and characterization (F1: 79.47%) of wheeze. Subsequently, we develop novel wheeze metrics, which show a significant correlation (Pearson’s correlation: -0.22, p-value: 0.024) with standard spirometry measure of pulmonary obstruction severity. This work takes a principal step towards the unobtrusive assessment of pulmonary condition from mobile sensor interactions.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI, 15</abbr>
    
  
  </div>

  <div id="10.1145/2702123.2702334" class="col-sm-8">
    
      <div class="title">Privacy Concerns and Behaviors of People with Visual Impairments</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Hoyle, Roberto,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Connelly, Kay,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Crandall, David,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Kapadia, Apu
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Various technologies have been developed to help make the world more accessible to visually impaired people, and recent advances in low-cost wearable and mobile computing are likely to drive even moreadvances. However, the unique privacy and security needs of visually impaired people remain largely unaddressed. We conducted an exploratory user study with 14 visually impaired participants to understand the techniques they currently use for protecting privacy, their remaining privacy concerns,and how new technologies may be able to help. The interviews explored privacy not only in the physical world (e.g., bystanders overhearing private conversations) and the online world (e.g., determining if a URL is legitimate), but also in the interface between the two (e.g. bystanders ‘shoulder-surfing’ data from screens). The study revealed serious concerns that are not adequately solved by current technology, and suggested new directions for improving the privacy of this significant fraction of the population.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">CHI,15</abbr>
    
  
  </div>

  <div id="10.1145/2702123.2702370" class="col-sm-8">
    
      <div class="title">Crowdsourced Exploration of Security Configurations</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ismail, Qatrunnada,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kapadia, Apu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Reiter, Michael K.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems</em>
      
      
        2015
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
      
      <a href="/assets/pdf/crowdperm.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank">PDF</a>
      
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Smartphone apps today request permission to access a multitude of sensitive resources, which users must accept completely during installation (e.g., on Android) or selectively configure after installation (e.g., on iOS, but also planned for Android). Everyday users, however, do not have the ability to make informed decisions about which permissions are essential for their usage. For enhanced privacy, we seek to leverage crowdsourcing to find minimal sets of permissions that will preserve the usability of the app for diverse users. We advocate an efficient ’lattice-based’ crowd-management strategy to explore the space of permissions sets. We conducted a user study (N = 26) in which participants explored different permission sets for the popular Instagram app. This study validates our efficient crowd management strategy and shows that usability scores for diverse users can be predicted accurately, enabling suitable recommendations.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">ICMI, 20</abbr>
    
  
  </div>

  <div id="Ahmed2020" class="col-sm-8">
    
      <div class="title">Automated Time Synchronization of Cough Events from Multimodal Sensors in Mobile Devices</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ahmed, M.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Rahman, M.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nemati, E.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Islam, B.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Vatanparvar, K.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nathan, V.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  McCaffrey, D.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kuang, J.,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gao, A.
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the 2020 International Conference on Multimodal Interaction</em>
      
      
        2020
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Tracking the type and frequency of cough events is critical for monitoring respiratory diseases. Coughs are one of the most common symptoms of respiratory and infectious diseases like COVID-19, and a cough monitoring system could have been vital in remote monitoring during a pandemic like COVID-19. While the existing solutions for cough monitoring use unimodal (e.g., audio) approaches for detecting coughs, a fusion of multimodal sensors (e.g., audio and accelerometer) from multiple devices (e.g., phone and watch) are likely to discover additional insights and can help to track the exacerbation of the respiratory conditions. However, such multimodal and multidevice fusion requires accurate time synchronization, which could be challenging for coughs as coughs are usually concise events (0.3-0.7 seconds). In this paper, we first demonstrate the time synchronization challenges of cough synchronization based on the cough data collected from two studies. Then we highlight the performance of a cross-correlation based time synchronization algorithm on the alignment of cough events. Our algorithm can synchronize 98.9% of cough events with an average synchronization error of 0.046s from two devices.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">EMBC, 21</abbr>
    
  
  </div>

  <div id="9631109" class="col-sm-8">
    
      <div class="title">RRMonitor: A Resource-Aware End-to-End System for Continuous Monitoring of Respiration Rate Using Earbuds</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  M, Md Mahbubur Rahman,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Mohsin,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Nemati, Ebrahim,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Ding, Minh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Folkman, Nathan,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kuang, Jilong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Gao, Alex
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2021 43rd Annual International Conference of the IEEE Engineering in Medicine   Biology Society (EMBC)</em>
      
      
        2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Respiration rate is considered as a critical vital sign, and daily monitoring of respiration rate could provide helpful information about any acute condition in the human body. While researchers have been exploring mobile devices for respiration rate monitoring, passive and continuous monitoring is still not feasible due to many usability challenges (e.g., active participation) in existing approaches. This paper presents an end-to-end system called RRMonitor that leverages the movement sensors from commodity earbuds to continuously monitor the respiration rate in near real-time. While developing the systems, we extensively explored some key parameters, algorithms, and approaches from existing literature that are better suited for continuous and passive respiration rate monitoring. RRMonitor can passively track the respiration rate with a mean absolute error as low as 1.64 cycles per minute without requiring active participation from the user.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-2 abbr">
  
    
    <abbr class="badge">IMWUT, 18</abbr>
    
  
  </div>

  <div id="Ahmed-IMWUT18" class="col-sm-8">
    
      <div class="title">Up to a Limit? Privacy Concerns of Bystanders and Their Willingness to Share Additional Information with Visually Impaired Users of Assistive Technologies</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Ahmed, Tousif,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Kapadia, Apu,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Potluri, Venkatesh,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Swaminathan, Manohar
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies (IMWUT)</em>
      
      
        2018
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>The emergence of augmented reality and computer vision based tools offer new opportunities to visually impaired persons (VIPs). Solutions that help VIPs in social interactions by providing information (age, gender, attire, expressions etc.) about people in the vicinity are becoming available. Although such assistive technologies are already collecting and sharing such information with VIPs, the views, perceptions, and preferences of sighted bystanders about such information sharing remain unexplored. Although bystanders may be willing to share more information for assistive uses it remains to be explored to what degree bystanders are willing to share various kinds of information and what might encourage additional sharing of information based on the contextual needs of VIPs. In this paper we describe the first empirical study of information sharing preferences of sighted bystanders of assistive devices. We conducted a survey based study using a contextual method of inquiry with 62 participants followed by nine semi-structured interviews to shed more insight on our key quantitative findings. We find that bystanders are more willing to share some kinds of personal information with VIPs and are willing to share additional information if higher security assurances can be made by improving their control over how their information is shared.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
</div>

      

     
    </article>

  </div>
</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2022 Tousif  Ahmed.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
    
    Last updated: March 14, 2022.
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  

  



<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
